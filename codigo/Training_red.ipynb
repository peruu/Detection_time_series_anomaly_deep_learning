{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_stack(x,size_step,size_trayect):\n",
    "    n = x.shape[0]\n",
    "    list_trayect = list()\n",
    "    for i in range(0,size_trayect):\n",
    "        aux = x[i:1+n+i-size_trayect:size_step]\n",
    "        list_trayect.append(aux)\n",
    "    return np.hstack(list_trayect) \n",
    "\n",
    "def explained_variance_score(y_true,y_pred):\n",
    "    error = y_true - y_pred\n",
    "    var_error = K.sum(K.square(error - K.mean(error)))\n",
    "    var_true = K.sum(K.square(y_true - K.mean(y_pred)))\n",
    "    return (1 - (var_error/var_true))\n",
    "\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "\n",
    "\n",
    "def autoencoder(input_shape):\n",
    "    model = Sequential(name=\"Autoencoder\")\n",
    "    # Encoder\n",
    "    model.add(layers.InputLayer(input_shape= input_shape)) # 20x12x1\n",
    "    model.add(layers.Conv2D(16, kernel_size=(1, 6),strides=(1,6),activation='tanh',padding='valid',name=\"conv_1\")) # 20x2x16\n",
    "    model.add(layers.Conv2D(32, kernel_size=(1, 2),activation='tanh',padding='valid',name=\"conv_2\")) # 20x1x32\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 1),strides=(2,1),activation='tanh',padding='same',name=\"conv_3\")) # 10x1x64\n",
    "    model.add(layers.Conv2D(128, kernel_size=(2, 1),strides=(2,1),activation='tanh',padding='valid',name=\"conv_4\")) # 5x1x128\n",
    "    model.add(layers.Flatten(name=\"flatten_1\")) # 640\n",
    "    # Coding\n",
    "    model.add(layers.Dense(300,activation='tanh',name=\"dense_1\")) # 300\n",
    "    model.add(layers.Dense(640,activation='tanh',name=\"dense_2\")) # 640\n",
    "    # Decoder\n",
    "    model.add(layers.Reshape((5,1,128),name=\"reshape_1\")) # 5x1x128\n",
    "    model.add(layers.Conv2DTranspose(64, kernel_size=(2, 1),strides=(2,1),activation='tanh',padding='valid',name=\"deconv_1\")) # 10x1x64\n",
    "    model.add(layers.Conv2DTranspose(32,kernel_size=(3,1), strides=(2, 1), activation='tanh',padding='same',name=\"deconv_2\")) # 20x1x32\n",
    "    model.add(layers.Conv2DTranspose(16,kernel_size=(1,2), strides=(1, 2), activation='tanh',padding='valid',name=\"deconv_3\")) # 20x2x16\n",
    "    model.add(layers.Conv2DTranspose(1,kernel_size=(1,6), strides=(1, 6), activation='tanh',padding='valid',name=\"deconv_4\")) # 20x12x1\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer data de archivo hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data_gps.hdf5', 'a') as data:\n",
    "    X_train = [ data[\"X_train\"][v][:] for v in list(data[\"X_train\"].keys())]\n",
    "    X_valid = [ data[\"X_valid\"][v][:] for v in list(data[\"X_valid\"].keys())]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros para tranformar datos gps a series de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_step, size_trayect = 39, 40 \n",
    "# Cambiar forma de entrada, solo usar para redes convolucionales. Comentar esta linea en caso de usar red autoencoder apilado\n",
    "height, width = 20,12 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [ window_stack(x,size_step, size_trayect) for x in X_train ]\n",
    "X_train = np.concatenate(X_train,axis=0)\n",
    "X_train = np.reshape(X_train, (len(X_train), height, width, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar data valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = [ window_stack(x,size_step, size_trayect) for x in X_valid ]\n",
    "X_valid = np.concatenate(X_valid,axis=0)\n",
    "X_valid = np.reshape(X_valid, (len(X_valid), height, width, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train y valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  (612846, 20, 12, 1)\n",
      "X_valid :  (216738, 20, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train : \",X_train.shape)\n",
    "print(\"X_valid : \",X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitectura red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rsoria/env/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_1 (Conv2D)              (None, 20, 2, 16)         112       \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 20, 1, 32)         1056      \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 10, 1, 64)         6208      \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 5, 1, 128)         16512     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               192300    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 640)               192640    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 5, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "deconv_1 (Conv2DTranspose)   (None, 10, 1, 64)         16448     \n",
      "_________________________________________________________________\n",
      "deconv_2 (Conv2DTranspose)   (None, 20, 1, 32)         6176      \n",
      "_________________________________________________________________\n",
      "deconv_3 (Conv2DTranspose)   (None, 20, 2, 16)         1040      \n",
      "_________________________________________________________________\n",
      "deconv_4 (Conv2DTranspose)   (None, 20, 12, 1)         97        \n",
      "=================================================================\n",
      "Total params: 432,589\n",
      "Trainable params: 432,589\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:] \n",
    "model = autoencoder(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# configuracion\n",
    "nb_epoch = 300\n",
    "batch_size = 32\n",
    "model.compile(optimizer='sgd', loss='mse',metrics=[r2,explained_variance_score])\n",
    "model.fit(X_train,X_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          validation_data=(X_valid,X_valid),\n",
    "          callbacks=[TensorBoard(log_dir='./logs/')])\n",
    "model.save(\"./autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
